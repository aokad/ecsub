#! /usr/bin/env python
# -*- coding: utf-8 -*-

"""
Created on Wed Mar 14 11:53:04 2018

@author: Okada
"""

import sys
import argparse
import ecsub.submit as submit
import ecsub.batch as batch
import ecsub.delete as delete
import ecsub.report as report
import ecsub.log as log
from ecsub import __version__
        
def main():
    prog = "ecsub"
    parser = argparse.ArgumentParser(prog = prog)
    parser.add_argument("--version", action = "version", version = prog + "-" + __version__)
    subparsers = parser.add_subparsers()
    
    def _create_submit_parser(subparsers, sub_command, help_text):
        
        default = submit.Argments()
    
        submit_parser = subparsers.add_parser(sub_command, help = help_text)
        submit_parser.add_argument("--wdir", metavar = "path/to/dir", help = "output temporary data", type = str, default = default.wdir)
        submit_parser.add_argument("--image", metavar = "docker/image:tag", help = "docker image", type = str, default = default.image)
        submit_parser.add_argument("--use_amazon_ecr", help = "use_amazon_ecr", action = 'store_true')
        submit_parser.add_argument("--shell", metavar = "path/to/bash", help = "path to bash or ash in docker-container", type = str, default = default.shell)
        submit_parser.add_argument("--setup-container-cmd", metavar = '"pip install awscli"', help = "awscli install command", type = str, default = default.setup_container_cmd)
        submit_parser.add_argument("--dind", help = "Docker in Docker?", action = 'store_true')
        submit_parser.add_argument("--script", metavar = "path/to/script.sh", help = "run script", type = str, required=True)
        submit_parser.add_argument("--tasks", metavar = "path/to/tasks.tsv", help = "parameters", type = str, required=True)
        submit_parser.add_argument("--task-name", metavar = "task-name", help = "submit name as AWS ECS cluster name", type = str, default = default.task_name)
        submit_parser.add_argument("--aws-s3-bucket", metavar = "s3://output/bucket", help = "AWS your S3 bucket", type = str, required=True)
        submit_parser.add_argument("--aws-ec2-instance-type", metavar = "t2.micro", help = "AWS instance type", type = str, default = default.aws_ec2_instance_type)
        submit_parser.add_argument("--aws-ec2-instance-type-list", metavar = "t3.micro,t2.micro", help = "AWS instance types, split with ',' ", type = str, default = default.aws_ec2_instance_type_list)
        submit_parser.add_argument("--disk-size", metavar = 22, help = "AWS disk size (GiB)", type = int, default = default.disk_size)
        submit_parser.add_argument("--processes", metavar = 20, help = "maximum multi processes", type = int, default = default.processes)
        submit_parser.add_argument("--aws-security-group-id", metavar = "sg-ab123456", help = "AWS your security_group_id", type = str, default =  default.aws_security_group_id)
        submit_parser.add_argument("--aws-key-name", metavar = "key-123ab", help = "AWS your key pair name", type = str, default = default.aws_key_name)
        submit_parser.add_argument("--aws-log-group-name", metavar = "lg-name", help = "AWS Cloudwatch Logs Log-group-name", type = str, default = default.aws_log_group_name)
        submit_parser.add_argument("--aws-subnet-id", metavar = "subnet-123456ab", help = "AWS subnet_id", type = str, default = default.aws_subnet_id)
        submit_parser.add_argument("--spot", help = "[spot] use spot instance", action = 'store_true')
        submit_parser.add_argument("--retry-od", help = "[spot] In case of failure, retry on demand instance", action = 'store_true')
        submit_parser.add_argument("--request-payer-bucket", metavar = "bucket-name", help = "Aware that you will be charged for downloading objects in requester pays buckets. Split with ',' ", type = str, default = default.request_payer_bucket)
        submit_parser.add_argument("--ignore-location", help = "Ignore differences in location", action = 'store_true')
        submit_parser.add_argument("--not-verify-bucket", help = "Do not verify input pathes", action = 'store_true')
        
        return submit_parser
        
    ##########
    # submit 
    submit_parser = _create_submit_parser(subparsers, "submit", "submit job")
    submit_parser.set_defaults(func = submit.entry_point)

    ##########
    # submit away
    away_parser = _create_submit_parser(subparsers, "away", "submit job, mode fly away")
    away_parser.set_defaults(func = submit.entry_point_flyaway)
    
    ##########
    # batch
    default = batch.Argments()
    batch_parser = subparsers.add_parser("batch", help = "Run with AWS Batch")
    batch_parser.add_argument("--script", metavar = "path/to/script.sh", help = "run script", type = str, required=True)
    batch_parser.add_argument("--tasks", metavar = "path/to/tasks.tsv", help = "parameters", type = str, required=True)
    batch_parser.add_argument("--task_name", metavar = "task-name", help = "AWS resources name", type = str, default = default.task_name)
    batch_parser.add_argument("--wdir", metavar = "path/to/dir", help = "output temporary data", type = str, default = default.wdir)
    batch_parser.add_argument("--image", metavar = "docker/image:tag", help = "docker image", type = str, default = default.image)
    batch_parser.add_argument("--shell", metavar = "path/to/bash", help = "path to bash or ash in docker-container", type = str, default = default.shell)
    batch_parser.add_argument("--setup_container_cmd", metavar = '"pip install awscli"', help = "awscli install command", type = str, default = default.setup_container_cmd)
    batch_parser.add_argument("--s3_bucket", metavar = "s3://output/bucket", help = "AWS your S3 bucket", type = str, required=True)
    batch_parser.add_argument("--instance_types", metavar = "c4.large,m5large", help = "AWS instance types, split with ','. [Attention] Do not use 't' family", type = str, default = default.instance_types)
    batch_parser.add_argument("--vcpu", metavar = 2, help = "The number of vCPUs reserved for the container.", type = int, default = default.vcpu)
    batch_parser.add_argument("--memory", metavar = 8, help = "The number of memory reserved for the container.", type = int, default = default.memory)
    batch_parser.add_argument("--disk_size", metavar = 22, help = "AWS disk size (GiB)", type = int, default = default.disk_size)
    batch_parser.add_argument("--processes", metavar = 20, help = "maximum multi processes", type = int, default = default.processes)
    batch_parser.add_argument("--security_groups", metavar = "sg-ab123456", help = "AWS your security_group_id, split with ','", type = str, default =  default.security_groups)
    batch_parser.add_argument("--key_name", metavar = "key-123ab", help = "AWS your key pair name", type = str, default = default.key_name)
    batch_parser.add_argument("--subnet_ids", metavar = "subnet-123456ab", help = "AWS subnet_id, split with ','", type = str, default = default.subnet_ids)
    batch_parser.add_argument("--use_amazon_ecr", help = "Use Amazon ECR", action = 'store_true')
    batch_parser.add_argument("--dind", help = "Docker in Docker?", action = 'store_true')
    batch_parser.add_argument("--spot", help = "Use SPOT instance", action = 'store_true')
    batch_parser.add_argument("--gpu", help = "Use GPU instance", action = 'store_true')
    batch_parser.add_argument("--request_payer_bucket", metavar = "bucket-name", help = "Aware that you will be charged for downloading objects in requester pays buckets. Split with ',' ", type = str, default = default.request_payer_bucket)
    batch_parser.add_argument("--ignore_location", help = "Ignore differences in location", action = 'store_true')
    batch_parser.add_argument("--not_verify_bucket", help = "Do not verify input pathes", action = 'store_true')
    batch_parser.add_argument("--wait", help = "Wait for completion", action = 'store_true')
    batch_parser.set_defaults(func = batch.entry_point)
    
    ##########
    # report 
    report_parser = subparsers.add_parser("report", help = "view report")
    report_parser.add_argument("--wdir", metavar = "path/to/dir", help = "{PATH} when 'ecsub submit --wdir {PATH}'", type = str, default = "./")
    report_parser.add_argument("-f", "--failed", help = "display failed or abnoraml exit status job only.", action = 'store_true')
    report_parser.add_argument("-b", "--begin", metavar = "[YYYYMMDDhhmm]", help = "The earliest createdAt time for jobs to be summarized, in the format [YYYYMMDDhhmm]", type = str, default = "")
    report_parser.add_argument("-e", "--end", metavar = "[YYYYMMDDhhmm]", help = "The latest createdAt time for jobs to be summarized, in the format [YYYYMMDDhhmm]", type = str, default = "")
    report_parser.add_argument("--max", metavar = "20", help = "Maximum display count", type = int, default = 0)
    report_parser.add_argument("--sortby", metavar = "sort_key", choices=[
            "exit_code",
            "taskname",
            "job_startAt",
            "job_endAt",
            "instance_type",
            "cpu",
            "memory",
            "disk_size",
            "price",
            "instance_createAt",
            "instance_stopAt"
        ], help = "Sort summary key", default = "taskname")
    report_parser.set_defaults(func = report.entry_point)
    
    ##########
    # delete
    delete_parser = subparsers.add_parser("delete", help = "delete job")
    delete_parser.add_argument("task_name", metavar = "task-name", help = "task name", type = str)
    delete_parser.add_argument("--wdir", metavar = "path/to/dir", help = "{PATH} when 'ecsub submit --wdir {PATH}'", type = str, default = "./")
    delete_parser.set_defaults(func = delete.entry_point)
    
    ##########
    # log stream 
    log_parser = subparsers.add_parser("logs", help = "download logs")
    log_parser.add_argument("mode", choices=['download', 'remove-log-group', 'remove-log-stream'], help = "mode")
    log_parser.add_argument("--wdir", metavar = "path/to/dir", help = "{PATH} when 'ecsub submit --wdir {PATH}'", type = str, default = "./")
    log_parser.add_argument("--log-group-prefix", metavar = "log-group-name-prefix", help = "prefix of LogGroupName in AWS CloudWatch", type = str, default = "")
    log_parser.add_argument("--log-group-name", metavar = "log-group-name", help = "LogGroupName in AWS CloudWatch", type = str, default = "")
    log_parser.add_argument("--log-stream-prefix", metavar = "log-stream-name-prefix", help = "prefix of LogStreamName in AWS CloudWatch", type = str, default = "")
    log_parser.add_argument("--tail", help = "flag for download from AWS", action = 'store_true')
    log_parser.set_defaults(func = log.entry_point)

    argv = sys.argv[1:]
    if len(argv) < 1:
        argv = [""]
        
    args = parser.parse_args(argv)
    
    return args.func(args)
    
if __name__ == "__main__":
    print (">>> " + " ".join(sys.argv))
    sys.exit(main())
